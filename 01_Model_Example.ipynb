{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "from typing import List, Union\n",
    "\n",
    "import ee\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "from google.oauth2 import service_account\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set these with your values\n",
    "# Path to service account key file\n",
    "os.environ['GA_AUTH_FILE']=''\n",
    "# Service account address\n",
    "os.environ['GEE_SERVICE_ACCOUNT']=''\n",
    "\n",
    "def authenticate(key_file: str = os.environ[\"GA_AUTH_FILE\"]) -> AuthorizedSession:\n",
    "\n",
    "    gcs_credentials = service_account.Credentials.from_service_account_file(key_file)\n",
    "    ee_creds = ee.ServiceAccountCredentials(os.environ[\"GEE_SERVICE_ACCOUNT\"], key_file)\n",
    "    ee.Initialize(ee_creds)\n",
    "    scoped_credentials = gcs_credentials.with_scopes(\n",
    "        [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "    )\n",
    "\n",
    "    return AuthorizedSession(scoped_credentials)\n",
    "\n",
    "\n",
    "compute_url = \"https://earthengine.googleapis.com/v1beta/projects/earthengine-public/image:computePixels\"\n",
    "\n",
    "\n",
    "def get_asset_url(asset_id):\n",
    "    name = f\"projects/earthengine-public/assets/{asset_id}\"\n",
    "    return f\"https://earthengine.googleapis.com/v1beta/{name}\"\n",
    "\n",
    "\n",
    "def get_asset_info(asset_id, session):\n",
    "    return json.loads(session.get(get_asset_url(asset_id)).content)\n",
    "\n",
    "\n",
    "def get_chip(\n",
    "    coords: List,\n",
    "    image: Union[str, ee.Image],\n",
    "    scale: float,\n",
    "    session: AuthorizedSession,\n",
    "):\n",
    "    query = {\n",
    "        \"fileFormat\": \"NPY\",\n",
    "        \"grid\": {\n",
    "            \"affineTransform\": {\n",
    "                \"scaleX\": scale,\n",
    "                \"scaleY\": scale,\n",
    "                \"translateX\": coords[0],\n",
    "                \"translateY\": coords[1],\n",
    "            },\n",
    "            \"dimensions\": {\"width\": 512, \"height\": 512},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if isinstance(image, (ee.Image)):\n",
    "        url = compute_url\n",
    "        query[\"expression\"] = ee.serializer.encode(image)\n",
    "    else:\n",
    "        url = get_asset_url(image) + \":getPixels\"\n",
    "\n",
    "    chip_response = session.post(url, json.dumps(query))\n",
    "\n",
    "    chip = np.load(io.BytesIO(chip_response.content)).astype(\"float32\")\n",
    "    # Pulls out nodata values\n",
    "    return np.where(chip < 0.0, 0.0, chip)\n",
    "\n",
    "\n",
    "def get_chips(\n",
    "    pt_tf, feature_image, label_image, scale, session\n",
    "):\n",
    "    feature_chip = get_chip(\n",
    "        pt_tf.numpy().tolist(), feature_image, scale, session\n",
    "    )\n",
    "\n",
    "    label_chip = get_chip(\n",
    "        pt_tf.numpy().tolist(), label_image, scale, session\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        np.expand_dims(np.expand_dims(feature_chip, axis=0), axis=-1),\n",
    "        np.expand_dims(np.expand_dims(label_chip, axis=0), axis=-1),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_points(n=100):\n",
    "    countries = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level0\")\n",
    "    germany = countries.filter(ee.Filter.eq(\"ADM0_NAME\", \"Germany\"))\n",
    "    pts = ee.FeatureCollection.randomPoints(region=germany, points=n)\n",
    "    return tf.convert_to_tensor(pts.geometry().coordinates().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1200/1200 [==============================] - 563s 453ms/step - loss: 15.2204 - root_mean_squared_error: 3.9013 - val_loss: 14.6410 - val_root_mean_squared_error: 3.8264\n",
      "Epoch 2/5\n",
      "1200/1200 [==============================] - 112s 93ms/step - loss: 11.0934 - root_mean_squared_error: 3.3307 - val_loss: 17.6077 - val_root_mean_squared_error: 4.1962\n",
      "Epoch 3/5\n",
      "1200/1200 [==============================] - 113s 94ms/step - loss: 7.5071 - root_mean_squared_error: 2.7399 - val_loss: 9.0079 - val_root_mean_squared_error: 3.0013\n",
      "Epoch 4/5\n",
      "1200/1200 [==============================] - 114s 95ms/step - loss: 5.7108 - root_mean_squared_error: 2.3897 - val_loss: 11.1372 - val_root_mean_squared_error: 3.3372\n",
      "Epoch 5/5\n",
      "1200/1200 [==============================] - 115s 96ms/step - loss: 4.7852 - root_mean_squared_error: 2.1875 - val_loss: 9.7272 - val_root_mean_squared_error: 3.1188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a7b727990>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import ee\n",
    "import tensorflow as tf\n",
    "from segmentation_models import Unet\n",
    "\n",
    "# I create a partial so we can use the map function with only a single\n",
    "# argument. I also wrap in tf.py_function since the data are retrieved\n",
    "# as numpy arrays and not tensors.\n",
    "def get_loaded_chips(pt_tf):\n",
    "    return tf.py_function(\n",
    "        partial(\n",
    "            get_chips,\n",
    "            feature_image=dem_id,\n",
    "            label_image=slope,\n",
    "            scale=scale,\n",
    "            session=session,\n",
    "        ),\n",
    "        [pt_tf],\n",
    "        [tf.float32, tf.float32],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataset(points):\n",
    "  return (\n",
    "      tf.data.Dataset.from_tensor_slices(points)\n",
    "      .map(get_loaded_chips, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .prefetch(tf.data.AUTOTUNE)\n",
    "      .cache()\n",
    "  )\n",
    "\n",
    "session = authenticate()\n",
    "# Shuttle Radar Topography Mission Digital Elevation Model\n",
    "dem_id = \"CGIAR/SRTM90_V4\"\n",
    "slope = ee.Terrain.slope(ee.Image(dem_id))\n",
    "\n",
    "# Retrieve the native scale of the DEM. It is in EPSG:4326,\n",
    "# so the points are in the correct transformation.\n",
    "dem_info = get_asset_info(dem_id, session)\n",
    "scale = dem_info[\"bands\"][0][\"grid\"][\"affineTransform\"][\"scaleX\"]\n",
    "\n",
    "dataset = get_dataset(get_points(1200))\n",
    "v_dataset = get_dataset(get_points(400))\n",
    "\n",
    "# Unet model with resnet34 backbone. Since the feature data only\n",
    "# has one band, we need to change the input weight and set `encoder_weights` to \n",
    "# None. We also change the activation function since we're modeling a \n",
    "#quantitative output.\n",
    "\n",
    "model = Unet(\n",
    "    \"resnet34\",\n",
    "    input_shape=(None, None, 1),\n",
    "    activation=\"linear\",\n",
    "    classes=1,\n",
    "    encoder_weights=None,\n",
    ")\n",
    "\n",
    "model.compile(\"SGD\", \"MeanSquaredError\", [\"RootMeanSquaredError\"])\n",
    "model.fit(dataset, batch_size=25, epochs=5, validation_data=v_dataset) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of gee-chipper.ipynb",
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
